
.. blogpost::
    :title: Plan séance 5
    :keywords: plan
    :date: 2022-02-25
    :categories: session

    Voici le plan prévu pour la première séance
    du cours de machine learning pour l'économie et
    la finance.

    **Séance 5 - partie 1**

    * json, rest, javascript
    * `analyse de survie
      <http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/survival_analysis.html>`_

    **Séance 5 - partie 2**

    * interprétabilité, `LIME <https://arxiv.org/pdf/1602.04938v1.pdf>`_,
      `Shapeley <https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf>`_,
      `Counter Factual
      <https://christophm.github.io/interpretable-ml-book/counterfactual.html>`_,
      `Partial Dependence
      <https://scikit-learn.org/stable/modules/partial_dependence.html>`_
    * biais en machine learning
    * `machine learning éthique
      <http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/ml2a/td2a_mlplus_machine_learning_ethique.html>`_
    * le projet, un modèle, analyser trois observations mal prédites,
      utiliser un des outils pour interpréter, en déduire une explication,
      suggérer une amélioration du modèle ou des variables
      pour corriger ces erreurs

    *A propros des biais*

    * `Calibration for the (Computationally-Identifiable) Masses
      <https://arxiv.org/abs/1711.08513>`_
    * `Outcome Indistinguishability
      <https://www-cs.stanford.edu/~mpkim/pubs/OI.pdf>`_
    * `L'équité de l'apprentissage machine en assurance
      <https://hal.archives-ouvertes.fr/hal-03561709/document>`_
    * `Machine Learning éthique
      <http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/ml2a/td2a_mlplus_machine_learning_ethique.html>`_
    * `Interprétabilité des modèles
      <http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/ml2a/td2a_mlplus_interpretabilite_des_modeles.html>`_

    Extraits :

    * Les biais de type 1 sont liés à des classes qui ne reflèteraient pas la réalité
      du risque, mais seraient motivés par de purs préjugés (critique qui ne remet
      pas en question le principe du bien-fondé de la classification). Justifiée en
      amont par le mythe d'une causalité des signes astrologiques sur les
      accidents par exemple, une classification zodiacale se révèlerait à l'usage
      comme « biaisée », au sens trivial où le modèle est faux ;
    * Les biais de type 2 sont liés à des classes qui reflètent une réalité statistique
      avérée (une corrélation avec le risque, donc un modèle exact) mais non
      causale, ce qui rend leur usage suspect d'un parti-pris et d'un choix
      arbitraire. C'est le cas par exemple du paramètre homme/femme. Là aussi
      on admet le bien-fondé d'une classification qui s'appuierait uniquement sur
      des variables causales, mais la corrélation seule ne donne pas lieu à une
      explication acceptable ;
    * Les biais de types 3 sont liés à des classes qui reflètent une réalité statistique
      et causale, mais qui est elle-même le fait de discriminations sociales en
      amont. Dans ce cas, le modèle est exact mais la classification est
      intrinsèquement nuisible car elle reproduit et ancre dans la réalité une
      situation contre laquelle il faut lutter.

    *Machine Learning privé*

    * `Calibrating Noise to Sensitivity in Private Data Analysis
      <https://iacr.org/archive/tcc2006/38760266/38760266.pdf>`_
    * `The Algorithmic Foundations of Differential Privacy
      <https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf>`_

    *Projets*
